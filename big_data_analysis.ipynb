{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHvHCj7as2vdhYW3J23Awi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratiksha806/dataAnaylis/blob/main/big_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEqMbJelV_gG",
        "outputId": "1b43ecc5-aaf1-421f-bbb2-00b24ebe8b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "|Order ID|    Date|      Product|   Category|Price|Quantity|Total Sales|Customer Name|Customer Location|Payment Method|   Status|\n",
            "+--------+--------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "| ORD0001|14-03-25|Running Shoes|   Footwear|   60|       3|        180|   Emma Clark|         New York|    Debit Card|Cancelled|\n",
            "| ORD0002|20-03-25|   Headphones|Electronics|  100|       4|        400|Emily Johnson|    San Francisco|    Debit Card|  Pending|\n",
            "| ORD0003|15-02-25|Running Shoes|   Footwear|   60|       2|        120|     John Doe|           Denver|    Amazon Pay|Cancelled|\n",
            "| ORD0004|19-02-25|Running Shoes|   Footwear|   60|       3|        180|Olivia Wilson|           Dallas|   Credit Card|  Pending|\n",
            "| ORD0005|10-03-25|   Smartwatch|Electronics|  150|       3|        450|   Emma Clark|         New York|    Debit Card|  Pending|\n",
            "+--------+--------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Order ID: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Price: integer (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Total Sales: integer (nullable = true)\n",
            " |-- Customer Name: string (nullable = true)\n",
            " |-- Customer Location: string (nullable = true)\n",
            " |-- Payment Method: string (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "+--------+----------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "|Order ID|      Date|      Product|   Category|Price|Quantity|Total Sales|Customer Name|Customer Location|Payment Method|   Status|\n",
            "+--------+----------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "| ORD0001|2025-03-14|Running Shoes|   Footwear| 60.0|       3|      180.0|   Emma Clark|         New York|    Debit Card|Cancelled|\n",
            "| ORD0002|2025-03-20|   Headphones|Electronics|100.0|       4|      400.0|Emily Johnson|    San Francisco|    Debit Card|  Pending|\n",
            "| ORD0003|2025-02-15|Running Shoes|   Footwear| 60.0|       2|      120.0|     John Doe|           Denver|    Amazon Pay|Cancelled|\n",
            "| ORD0004|2025-02-19|Running Shoes|   Footwear| 60.0|       3|      180.0|Olivia Wilson|           Dallas|   Credit Card|  Pending|\n",
            "| ORD0005|2025-03-10|   Smartwatch|Electronics|150.0|       3|      450.0|   Emma Clark|         New York|    Debit Card|  Pending|\n",
            "+--------+----------+-------------+-----------+-----+--------+-----------+-------------+-----------------+--------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---------------+------------+\n",
            "|        Product|TotalRevenue|\n",
            "+---------------+------------+\n",
            "|   Refrigerator|     78000.0|\n",
            "|         Laptop|     58400.0|\n",
            "|     Smartphone|     48500.0|\n",
            "|Washing Machine|     27000.0|\n",
            "|     Smartwatch|     15750.0|\n",
            "+---------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------+----------+\n",
            "|Customer Name|TotalSpent|\n",
            "+-------------+----------+\n",
            "|Olivia Wilson|   36170.0|\n",
            "|   Jane Smith|   31185.0|\n",
            "|   Emma Clark|   29700.0|\n",
            "|     John Doe|   26870.0|\n",
            "|Emily Johnson|   23475.0|\n",
            "+-------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Step 1: Import Required Libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum as _sum, count, avg, to_date\n",
        "\n",
        "# üî• Step 2: Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Amazon Sales Data Analysis 2025\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# üìÅ Step 3: Load Dataset\n",
        "file_path = \"sample_data/amazon_sales_data 2025.csv\"  # If using locally, update this path\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# üîç Step 4: Preview Data\n",
        "df.show(5)\n",
        "df.printSchema()\n",
        "# Convert Date string to proper date format\n",
        "df = df.withColumn(\"Date\", to_date(col(\"Date\"), \"dd-MM-yy\"))\n",
        "\n",
        "# Cast numerical columns\n",
        "df = df.withColumn(\"Price\", col(\"Price\").cast(\"double\")) \\\n",
        "       .withColumn(\"Quantity\", col(\"Quantity\").cast(\"int\")) \\\n",
        "       .withColumn(\"Total Sales\", col(\"Total Sales\").cast(\"double\"))\n",
        "\n",
        "# Drop rows with any nulls in important fields\n",
        "df_clean = df.dropna(subset=[\"Date\", \"Product\", \"Category\", \"Price\", \"Quantity\", \"Total Sales\"])\n",
        "\n",
        "df_clean.show(5)\n",
        "top_products = df_clean.groupBy(\"Product\") \\\n",
        "    .agg(_sum(\"Total Sales\").alias(\"TotalRevenue\")) \\\n",
        "    .orderBy(col(\"TotalRevenue\").desc())\n",
        "\n",
        "top_products.show(5)\n",
        "top_customers = df_clean.groupBy(\"Customer Name\") \\\n",
        "    .agg(_sum(\"Total Sales\").alias(\"TotalSpent\")) \\\n",
        "    .orderBy(col(\"TotalSpent\").desc())\n",
        "\n",
        "top_customers.show(5)\n",
        "top_products.write.csv(\"output/top_products.csv\", header=True)\n",
        "top_customers.write.csv(\"output/top_customers.csv\", header=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML & Spark tools\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Step 1: Filter & Prepare Data\n",
        "df_ml = df_clean.select(\"Product\", \"Category\", \"Price\", \"Quantity\", \"Customer Location\", \"Payment Method\", \"Status\")\n",
        "\n",
        "# Step 2: Encode Categorical Labels\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=col+\"_index\").fit(df_ml)\n",
        "    for col in [\"Product\", \"Category\", \"Customer Location\", \"Payment Method\", \"Status\"]\n",
        "]\n",
        "for indexer in indexers:\n",
        "    df_ml = indexer.transform(df_ml)\n",
        "\n",
        "# Step 3: Binary classification: Cancelled = 1, Others = 0\n",
        "df_ml = df_ml.withColumn(\"label\", when(col(\"Status_index\") == 0.0, 1).otherwise(0))  # adjust depending on index mapping\n",
        "\n",
        "# Step 4: Feature Vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Product_index\", \"Category_index\", \"Price\", \"Quantity\", \"Customer Location_index\", \"Payment Method_index\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_ready = assembler.transform(df_ml)\n",
        "\n",
        "# Step 5: Split Train/Test\n",
        "train_data, test_data = df_ready.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 6: Train Classifier (Logistic Regression)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "# Step 7: Predictions\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n",
        "\n",
        "# Step 8: Evaluate Model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miry9WISbSPz",
        "outputId": "0f60365c-e452-4caf-f831-8b0dd82fb78e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------------------+\n",
            "|label|prediction|         probability|\n",
            "+-----+----------+--------------------+\n",
            "|    1|       0.0|[0.61073771798179...|\n",
            "|    0|       0.0|[0.58934166687224...|\n",
            "|    0|       0.0|[0.66872100772732...|\n",
            "|    0|       0.0|[0.64424985424017...|\n",
            "|    0|       0.0|[0.61338408223597...|\n",
            "+-----+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Test Accuracy: 0.74\n"
          ]
        }
      ]
    }
  ]
}